<html><head>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META HTTP-EQUIV="Content-Language" CONTENT="en-US"><META NAME="robots" CONTENT="index, follow">
<META NAME="rating" CONTENT="General"><META NAME="distribution" CONTENT="Global">
<META NAME="revisit-after" CONTENT="15 days"><META NAME="author" CONTENT="Laurent Itti, JeVois">
<META NAME="description" CONTENT="JeVois Smart Embedded Machine Vision Toolkit - module DetectionDNN">
<link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
<link rel='stylesheet prefetch' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.min.css'>
<link rel="stylesheet" type="text/css" href="/modstyle.css">
</head> <body>
<table class=modinfo><tr><td>
<table class=modinfotop><tr><td><a href="/moddoc/DetectionDNN/modinfo.html"><img src="/moddoc/DetectionDNN/icon.png" width=48></a></td>
<td valign=middle><table><tr><td class=modinfoname>Detection DNN</td></tr>
<tr><td class=modinfosynopsis>Detect and recognize multiple objects in scenes using OpenCV Deep Neural Nets (DNN) </td></tr></table></td></tr></table></td></tr>
<tr><td width=100%><table class=modinfoauth width=100%><tr><td>By Laurent Itti</td><td align=center>itti@usc.edu</td><td align=center>http://jevois.org</td><td align=right>GPL v3</td></tr></table></td></tr>
<tr><td><table class=videomapping><tr><td class=videomapping>
<table class=moduledata><tr><td class=moduledata>&nbsp;Language:&nbsp;C++</td><td class=moduledata align=center>Supports mappings with USB output:&nbsp;Yes</td><td class=moduledata align=right>Supports mappings with NO USB output:&nbsp;Yes&nbsp;</td></tr></table>
</td></tr>
<tr><td class=videomapping><small><b>&nbsp;Video Mapping: &nbsp; </b></small><tt>NONE&nbsp;0&nbsp;0&nbsp;0.0&nbsp;YUYV&nbsp;640&nbsp;480&nbsp;15.0&nbsp;JeVois&nbsp;DetectionDNN</tt></td></tr>
<tr><td class=videomapping><small><b>&nbsp;Video Mapping: &nbsp; </b></small><tt>YUYV&nbsp;640&nbsp;498&nbsp;15.0&nbsp;YUYV&nbsp;640&nbsp;480&nbsp;15.0&nbsp;JeVois&nbsp;DetectionDNN</tt></td></tr>
</table></td></tr>
<tr><td><div class=container>
<div class=galleryItem><a href="screenshot1.png"><img src="screenshot1.png"></a></div>
</div></td></tr><tr><td class=modinfodesc><h2>Module Documentation</h2><div class="textblock"><p>This module runs an object detection deep neural network using the OpenCV DNN library. Detection networks analyze a whole scene and produce a number of bounding boxes around detected objects, together with identity labels and confidence scores for each detected box.</p>
<p>This module runs the selected deep neural network and shows all detections obtained.</p>
<p>Note that by default this module runs the OpenCV Face Detector DNN which can detect human faces.</p>
<p>Included with the standard JeVois distribution are the following networks:</p>
<ul>
<li>OpenCV Face Detector, Caffe model</li>
<li>MobileNet + SSD trained on Pascal VOC (20 object classes), Caffe model</li>
<li>MobileNet + SSD trained on Coco (80 object classes), TensorFlow model</li>
<li>MobileNet v2 + SSD trained on Coco (80 object classes), TensorFlow model</li>
<li>Darknet Tiny YOLO v3 trained on Coco (80 object classes), Darknet model</li>
<li>Darknet Tiny YOLO v2 trained on Pascal VOC (20 object classes), Darknet model</li>
</ul>
<p>See the module's <b>params.cfg</b> file to switch network. Object categories are as follows:</p>
<ul>
<li>The 80 COCO object categories are: person, bicycle, car, motorbike, aeroplane, bus, train, truck, boat, traffic, fire, stop, parking, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports, kite, baseball, baseball, skateboard, surfboard, tennis, bottle, wine, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot, pizza, donut, cake, chair, sofa, pottedplant, bed, diningtable, toilet, tvmonitor, laptop, mouse, remote, keyboard, cell, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy, hair, toothbrush.</li>
<li>The 20 Pascal-VOC object categories are: aeroplane, bicycle, bird, boat, bottle, bus, car, cat, chair, cow, diningtable, dog, horse, motorbike, person, pottedplant, sheep, sofa, train, tvmonitor.</li>
</ul>
<p>Sometimes it will make mistakes! The performance of yolov3-tiny is about 33.1% correct (mean average precision) on the COCO test set. The OpenCV Face Detector is quite fast and robust!</p>
<h2>Speed and network size </h2>
<p>The parameter <code>netin</code> allows you to rescale the neural network to the specified size. Beware that this will only work if the network used is fully convolutional (as is the case with the default networks listed above). This not only allows you to adjust processing speed (and, conversely, accuracy), but also to better match the network to the input images (e.g., the default size for tiny-yolo is 416x416, and, thus, passing it a input image of size 640x480 will result in first scaling that input to 416x312, then letterboxing it by adding gray borders on top and bottom so that the final input to the network is 416x416). This letterboxing can be completely avoided by just resizing the network to 320x240.</p>
<p>Here are expected processing speeds for the OpenCV Face Detector:</p><ul>
<li>when netin = [320 240], processes 320x240 inputs, about 650ms/image (1.5 frames/s)</li>
<li>when netin = [160 120], processes 160x120 inputs, about 190ms/image (5.0 frames/s)</li>
</ul>
<h2>Serial messages </h2>
<p>When detections are found which are above threshold, one message will be sent for each detected object (i.e., for each box that gets drawn when USB outputs are used), using a standardized 2D message:</p><ul>
<li>Serial message type: <b>2D</b> </li>
<li><code>id</code>: the category of the recognized object, followed by ':' and the confidence score in percent</li>
<li><code>x</code>, <code>y</code>, or vertices: standardized 2D coordinates of object center or corners</li>
<li><code>w</code>, <code>h</code>: standardized object size</li>
<li><code>extra</code>: any number of additional category:score pairs which had an above-threshold score for that box</li>
</ul>
<p>See <a class="elRef" doxygen="/lab/itti/jevois/software/jevois/doc/jevois.tag:/doc/" href="/doc/UserSerialStyle.html">Standardized serial messages formatting</a> for more on standardized serial messages, and <a class="elRef" doxygen="/lab/itti/jevois/software/jevois/doc/jevois.tag:/doc/" href="/doc/group__coordhelpers.html">Helper functions to convert coordinates from camera resolution to standardized</a> for more info on standardized coordinates.</p>
<p>This code is heavily inspired from: <a href="https://github.com/opencv/opencv/blob/master/samples/dnn/object_detection.cpp">https://github.com/opencv/opencv/blob/master/samples/dnn/object_detection.cpp</a></p>
</div></td></tr>
<tr><td><table class=modinfopar><tr><th class=modinfopar>Parameter</th><th class=modinfopar>Type</th><th class=modinfopar>Description</th><th class=modinfopar>Default</th><th class=modinfopar>Valid&nbsp;Values</th></tr>
<tr class=modinfopar><td class=modinfopar>(<A HREF="/basedoc/classDetectionDNN.html">DetectionDNN</A>) classnames</td><td class=modinfopar>std::string</td><td class=modinfopar>Path to a text file with names of classes to label detected objects</td><td class=modinfopar>/jevois/share/opencv-dnn/detection/opencv_face_detector.classes</td><td class=modinfopar>-</td></tr>
<tr class=modinfopar><td class=modinfopar>(<A HREF="/basedoc/classDetectionDNN.html">DetectionDNN</A>) configname</td><td class=modinfopar>std::string</td><td class=modinfopar>Path to a text file that contains network configuration. Can have extension .prototxt (Caffe), .pbtxt (TensorFlow), or .cfg (Darknet).</td><td class=modinfopar>/jevois/share/opencv-dnn/detection/opencv_face_detector.prototxt</td><td class=modinfopar>-</td></tr>
<tr class=modinfopar><td class=modinfopar>(<A HREF="/basedoc/classDetectionDNN.html">DetectionDNN</A>) modelname</td><td class=modinfopar>std::string</td><td class=modinfopar>Path to a binary file of model contains trained weights. Can have extension .caffemodel (Caffe), .pb (TensorFlow), .t7 or .net (Torch), or .weights (Darknet).</td><td class=modinfopar>/jevois/share/opencv-dnn/detection/opencv_face_detector.caffemodel</td><td class=modinfopar>-</td></tr>
<tr class=modinfopar><td class=modinfopar>(<A HREF="/basedoc/classDetectionDNN.html">DetectionDNN</A>) netin</td><td class=modinfopar>cv::Size</td><td class=modinfopar>Width and height (in pixels) of the neural network input layer, or [0 0] to make it match camera frame size. NOTE: for YOLO v3 sizes must be multiples of 32.</td><td class=modinfopar>cv::Size(160, 120)</td><td class=modinfopar>-</td></tr>
<tr class=modinfopar><td class=modinfopar>(<A HREF="/basedoc/classDetectionDNN.html">DetectionDNN</A>) thresh</td><td class=modinfopar>float</td><td class=modinfopar>Detection threshold in percent confidence</td><td class=modinfopar>50.0F</td><td class=modinfopar>jevois::Range&lt;float&gt;(0.0F, 100.0F)</td></tr>
<tr class=modinfopar><td class=modinfopar>(<A HREF="/basedoc/classDetectionDNN.html">DetectionDNN</A>) nms</td><td class=modinfopar>float</td><td class=modinfopar>Non-maximum suppression intersection-over-union threshold in percent</td><td class=modinfopar>45.0F</td><td class=modinfopar>jevois::Range&lt;float&gt;(0.0F, 100.0F)</td></tr>
<tr class=modinfopar><td class=modinfopar>(<A HREF="/basedoc/classDetectionDNN.html">DetectionDNN</A>) rgb</td><td class=modinfopar>bool</td><td class=modinfopar>When true, model works with RGB input images instead BGR ones</td><td class=modinfopar>true</td><td class=modinfopar>-</td></tr>
<tr class=modinfopar><td class=modinfopar>(<A HREF="/basedoc/classDetectionDNN.html">DetectionDNN</A>) scale</td><td class=modinfopar>float</td><td class=modinfopar>Value scaling factor applied to input pixels</td><td class=modinfopar>2.0F / 255.0F</td><td class=modinfopar>-</td></tr>
<tr class=modinfopar><td class=modinfopar>(<A HREF="/basedoc/classDetectionDNN.html">DetectionDNN</A>) mean</td><td class=modinfopar>cv::Scalar</td><td class=modinfopar>Mean BGR value subtracted from input image</td><td class=modinfopar>cv::Scalar(127.5F, 127.5F, 127.5F)</td><td class=modinfopar>-</td></tr>
</table></td></tr>
<tr><td><table class=modinfocfg><tr><td class=modinfocfg><b>params.cfg file</b><hr><pre># Parameter file for DetectionDNN. You can select a neural network to run here:

# OpenCV Face Detector, Caffe model
classnames = /jevois/share/opencv-dnn/detection/opencv_face_detector.classes
modelname = /jevois/share/opencv-dnn/detection/opencv_face_detector.caffemodel
configname = /jevois/share/opencv-dnn/detection/opencv_face_detector.prototxt
scale = 1.0
mean = 104.0 177.0 123.0
rgb = false

# MobileNet v2 + SSD trained on Coco (80 object classes), TensorFlow model
#classnames = /jevois/share/darknet/yolo/data/coco.names
#modelname = /jevois/share/opencv-dnn/detection/ssd_mobilenet_v2_coco_2018_03_29.pb
#configname = /jevois/share/opencv-dnn/detection/ssd_mobilenet_v2_coco_2018_03_29.pbtxt

# MobileNet + SSD trained on Pascal VOC (20 object classes), Caffe model
#classnames = /jevois/share/darknet/yolo/data/voc.names
#modelname = /jevois/share/opencv-dnn/detection/MobileNetSSD_deploy.caffemodel
#configname = /jevois/share/opencv-dnn/detection/MobileNetSSD_deploy.prototxt
#rgb = false

# MobileNet + SSD trained on Coco (80 object classes), TensorFlow model
#classnames = /jevois/share/darknet/yolo/data/coco.names
#modelname = /jevois/share/opencv-dnn/detection/ssd_mobilenet_v1_coco_2017_11_17.pb
#configname = /jevois/share/opencv-dnn/detection/ssd_mobilenet_v1_coco_2017_11_17.pbtxt
#rgb = false
#nms = 10.0

# Darknet Tiny YOLO v3 trained on Coco (80 object classes), Darknet model
#classnames = /jevois/share/darknet/yolo/data/coco.names
#modelname = /jevois/share/darknet/yolo/weights/yolov3-tiny.weights
#configname = /jevois/share/darknet/yolo/cfg/yolov3-tiny.cfg
            
# Darknet Tiny YOLO v2 trained on Pascal VOC (20 object classes), Darknet model
#classnames = /jevois/share/darknet/yolo/data/voc.names
#modelname = /jevois/share/darknet/yolo/weights/yolov2-tiny-voc.weights
#configname = /jevois/share/darknet/yolo/cfg/yolov2-tiny-voc.cfg
#netin = 320 240
</pre></td></tr></table></td></tr>
<tr><td><table class=modinfomisc>
<tr class=modinfomisc><th class=modinfomisc>Detailed docs:</th><td class=modinfomisc><A HREF="/basedoc/classDetectionDNN.html">DetectionDNN</A></td></tr>
<tr class=modinfomisc><th class=modinfomisc>Copyright:</th><td class=modinfomisc>Copyright (C) 2018 by Laurent Itti, iLab and the University of Southern California</td></tr>
<tr class=modinfomisc><th class=modinfomisc>License:</th><td class=modinfomisc>GPL v3</td></tr>
<tr class=modinfomisc><th class=modinfomisc>Distribution:</th><td class=modinfomisc>Unrestricted</td></tr>
<tr class=modinfomisc><th class=modinfomisc>Restrictions:</th><td class=modinfomisc>None</td></tr>
<tr class=modinfomisc><th class=modinfomisc>Support URL:</th><td class=modinfomisc>http://jevois.org/doc</td></tr>
<tr class=modinfomisc><th class=modinfomisc>Other URL:</th><td class=modinfomisc>http://iLab.usc.edu</td></tr>
<tr class=modinfomisc><th class=modinfomisc>Address:</th><td class=modinfomisc>University of Southern California, HNB-07A, 3641 Watt Way, Los Angeles, CA 90089-2520, USA</td></tr>
</table></td></tr>
</table>
</body></html>
